{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# seed = 1234\n",
    "# torch.manual_seed(seed)\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlated_mixtures(\n",
    "    components_num: int,\n",
    "    dim_num: int,\n",
    "    A=None,\n",
    "    b=None,\n",
    "    epsilon=1e-3\n",
    "):\n",
    "    \"\"\"\n",
    "    生成 comp1、comp2 这两组混合高斯分布，使得两者的各分量一一对应 (index 相同)。\n",
    "    其中 comp2[i] 的均值 = A * comp1[i] + b, 并做一点随机扰动。\n",
    "    协方差也可加扰动。\n",
    "    \"\"\"\n",
    "    if A is None:\n",
    "        # 缺省设为单位阵\n",
    "        A = torch.eye(dim_num)\n",
    "    if b is None:\n",
    "        # 缺省设为 0\n",
    "        b = torch.zeros(dim_num)\n",
    "\n",
    "    # comp1 的各分量\n",
    "    means1 = torch.randn(components_num, dim_num)   # 随机均值\n",
    "    covs1 = []\n",
    "    for _ in range(components_num):\n",
    "        # 随机生成正定协方差\n",
    "        M = torch.randn(dim_num, dim_num)\n",
    "        cov = M @ M.T + epsilon * torch.eye(dim_num)\n",
    "        covs1.append(cov)\n",
    "\n",
    "    # comp2 的各分量: 受 comp1 的参数影响（线性映射 + 随机扰动）\n",
    "    means2 = []\n",
    "    covs2 = []\n",
    "    for i in range(components_num):\n",
    "        mean2 = means1[i] @ A.T + b  # A是 (dim, dim)，外加一个可选偏置 b\n",
    "        # 给 means2 加一点随机噪声，以免完全重合\n",
    "        mean2 = mean2 + 0.02 * torch.randn(dim_num)\n",
    "\n",
    "        M2 = torch.randn(dim_num, dim_num)\n",
    "        cov2 = M2 @ M2.T + epsilon * torch.eye(dim_num)\n",
    "        # 也可以考虑把 cov1[i] 做相似变换： cov2 = A @ covs1[i] @ A.T + ...\n",
    "        # 这里只做简单的随机生成\n",
    "        covs2.append(cov2)\n",
    "        means2.append(mean2)\n",
    "\n",
    "    # 最终构建 D.MultivariateNormal\n",
    "    comp1 = []\n",
    "    comp2 = []\n",
    "    for i in range(components_num):\n",
    "        dist1 = D.MultivariateNormal(loc=means1[i], covariance_matrix=covs1[i])\n",
    "        dist2 = D.MultivariateNormal(loc=means2[i], covariance_matrix=covs2[i])\n",
    "        comp1.append(dist1)\n",
    "        comp2.append(dist2)\n",
    "\n",
    "    return comp1, comp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pairs_extra_dim(\n",
    "    comp1: list,\n",
    "    comp2: list,\n",
    "    N: int,\n",
    "    comp_var: int\n",
    "):\n",
    "    \"\"\"\n",
    "    从 comp1 和 comp2 (均为 List[MultivariateNormal], 长度 L) 中采样:\n",
    "      - 对每个样本 i:\n",
    "        1) 从 comp2[ main_idx_i ] 采样 -> sample2[i] (dim维)\n",
    "        2) 从 comp1[ main_idx_i ] 采样 1 个向量 + 再从 comp1 里随机抽 comp_var-1 个分量采样\n",
    "           拼接成 (comp_var * dim) 的向量 -> sample1[i]\n",
    "    返回:\n",
    "        sample1: shape (N, comp_var * dim)\n",
    "        sample2: shape (N, dim)\n",
    "    \"\"\"\n",
    "    assert len(comp1) == len(comp2), \"comp1 和 comp2 长度必须相同\"\n",
    "    L = len(comp1)\n",
    "    dim = comp1[0].mean.shape[0]\n",
    "    \n",
    "    # 创建结果张量\n",
    "    sample1 = torch.empty(N, comp_var * dim)\n",
    "    sample2 = torch.empty(N, dim)\n",
    "    \n",
    "    # 1) 随机生成每个样本的主要分量: main_indices\n",
    "    main_indices = torch.randint(0, L, (N,))\n",
    "    \n",
    "    # 2) 为额外 (comp_var - 1) 份采样生成随机分量索引: other_indices\n",
    "    if comp_var > 1:\n",
    "        other_indices = torch.randint(0, L, (N, comp_var - 1))\n",
    "    else:\n",
    "        # comp_var=1 时没有额外分量\n",
    "        other_indices = None\n",
    "    \n",
    "    # ================== A) 批量处理 “主要”分量 ==================\n",
    "    #    - 对 comp2[d] 做一次性采样 -> 填入 sample2\n",
    "    #    - 对 comp1[d] 做一次性采样 -> 填入 sample1[:, 0:dim]\n",
    "    for d in range(L):\n",
    "        # 找出 main_indices == d 的所有行\n",
    "        mask_i = (main_indices == d).nonzero(as_tuple=True)[0]\n",
    "        count_d = mask_i.shape[0]\n",
    "        if count_d == 0:\n",
    "            continue\n",
    "        \n",
    "        # 从 comp2[d] 批量采样 -> 放到 sample2[mask_i]\n",
    "        x2 = comp2[d].sample((count_d,))  # shape (count_d, dim)\n",
    "        sample2[mask_i] = x2\n",
    "        \n",
    "        # 从 comp1[d] 批量采样 -> 放到 sample1[mask_i, 0:dim]\n",
    "        x1_main = comp1[d].sample((count_d,))  # shape (count_d, dim)\n",
    "        sample1[mask_i, 0:dim] = x1_main\n",
    "    \n",
    "    # ================== B) 批量处理 “额外”分量 ==================\n",
    "    #   如果 comp_var=1，就不需要额外分量了\n",
    "    if comp_var > 1:\n",
    "        # other_indices 的 shape: (N, comp_var-1)\n",
    "        \n",
    "        # 遍历每个分量 d，集中处理\n",
    "        for d in range(L):\n",
    "            # 找出所有 (i, j) 使得 other_indices[i,j] = d\n",
    "            i_2d, j_2d = (other_indices == d).nonzero(as_tuple=True)\n",
    "            # 这样 i_2d 与 j_2d 形状相同, each pair (i_2d[k], j_2d[k]) 是一个位置\n",
    "            count_2d = i_2d.shape[0]\n",
    "            if count_2d == 0:\n",
    "                continue\n",
    "            \n",
    "            # 一次性从 comp1[d] 采样 count_2d 个 (dim,) 向量\n",
    "            x_d = comp1[d].sample((count_2d,))\n",
    "            \n",
    "            # 需要把 x_d[k] 填到 sample1[i_2d[k], offset: offset+dim],\n",
    "            #   其中 offset = (1 + j_2d[k]) * dim\n",
    "            #   (因为第0块已经是主要分量, 剩余的 j=0,1,...,comp_var-2 分别放第1..comp_var-1 块)\n",
    "            \n",
    "            # 为了批量赋值，需要对 j_2d 进行分组\n",
    "            # 下面示例做一个简单的循环, 以 j_2d 的取值为分组\n",
    "            unique_j = j_2d.unique()\n",
    "            \n",
    "            # 当前在 x_d 中的位置\n",
    "            cur_idx = 0\n",
    "            for j_val in unique_j:\n",
    "                # 本组大小\n",
    "                mask_this_j = (j_2d == j_val)\n",
    "                group_count = mask_this_j.sum().item()\n",
    "                # 取出在 x_d 里的对应部分\n",
    "                x_sub = x_d[cur_idx : cur_idx + group_count]\n",
    "                cur_idx += group_count\n",
    "                \n",
    "                # 找到对应的 i\n",
    "                i_sub = i_2d[mask_this_j]\n",
    "                \n",
    "                # 计算 sample1 对应的 offset\n",
    "                offset = (1 + j_val.item()) * dim\n",
    "                sample1[i_sub, offset : offset+dim] = x_sub\n",
    "    \n",
    "    return sample1, sample2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return F.relu(out + residual)\n",
    "\n",
    "class ResMLPBackbone(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_blocks=3):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, embed_dim)\n",
    "        self.blocks = nn.Sequential(*[ResidualBlock(embed_dim) for _ in range(num_blocks)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Loss (InfoNCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        # We'll train over log_temp to keep it in a stable range\n",
    "        self.log_temp = nn.Parameter(torch.log(torch.tensor(1/temperature)))\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        \"\"\"\n",
    "        emb1: shape (N, EMBED_DIM)\n",
    "        emb2: shape (N, EMBED_DIM)\n",
    "        Returns: scalar loss\n",
    "        \"\"\"\n",
    "        # Normalize embeddings\n",
    "        emb1 = F.normalize(emb1, dim=-1)  # shape (N, EMBED_DIM)\n",
    "        emb2 = F.normalize(emb2, dim=-1)  # shape (N, EMBED_DIM)\n",
    "\n",
    "        # Compute cosine similarities: (N, EMBED_DIM) x (N, EMBED_DIM) -> (N, N)\n",
    "        # Here, (N, E) dot (N, E) => we'll do it by matrix multiply\n",
    "        sim_matrix = emb1 @ emb2.T  # shape (N, N)\n",
    "\n",
    "        # Scale by temperature\n",
    "        temperature = torch.exp(self.log_temp)\n",
    "        logits = sim_matrix / temperature  # shape (N, N)\n",
    "\n",
    "        # We want each row i to match column i => label[i] = i\n",
    "        labels = torch.arange(emb1.size(0), device=emb1.device)\n",
    "\n",
    "        # Cross-entropy loss for emb1 -> emb2\n",
    "        loss_i = F.cross_entropy(logits, labels)\n",
    "        # Cross-entropy loss for emb2 -> emb1 (transpose)\n",
    "        loss_t = F.cross_entropy(logits.T, labels)\n",
    "\n",
    "        # Final contrastive loss\n",
    "        loss = (loss_i + loss_t) / 2.0\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1: torch.Size([512, 1]), sample2: torch.Size([512, 1])\n"
     ]
    }
   ],
   "source": [
    "num_steps = 50000\n",
    "batch_size = 256\n",
    "dim_num = 1\n",
    "comp_var = 1            # 样本拼接倍数，示例用 1\n",
    "components_num = 10000     # 混合分布中分量个数\n",
    "embed_dim = 128          # 编码后输出 embedding 的维度\n",
    "lr = 1e-4               # 学习率\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "encoder1 = ResMLPBackbone(input_dim=comp_var * dim_num, embed_dim=embed_dim, num_blocks=12)\n",
    "encoder2 = ResMLPBackbone(input_dim=dim_num, embed_dim=embed_dim, num_blocks=12)\n",
    "\n",
    "# criterion = ContrastiveLoss(temperature=0.07)\n",
    "\n",
    "params = list(encoder1.parameters()) + list(encoder2.parameters())\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "\n",
    "comp1, comp2 = make_correlated_mixtures(components_num, dim_num)\n",
    "\n",
    "sample1, sample2 = sample_pairs_extra_dim(comp1=comp1, comp2=comp2, N=N, comp_var=comp_var)\n",
    "print(f'sample1: {sample1.shape}, sample2: {sample2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [100/50000], loss = 5.5305\n",
      "step [200/50000], loss = 5.5304\n",
      "step [300/50000], loss = 5.5303\n",
      "step [400/50000], loss = 5.5334\n",
      "step [500/50000], loss = 5.5305\n",
      "step [600/50000], loss = 5.5310\n",
      "step [700/50000], loss = 5.5343\n",
      "step [800/50000], loss = 5.5291\n",
      "step [900/50000], loss = 5.5307\n",
      "step [1000/50000], loss = 5.5297\n",
      "step [1100/50000], loss = 5.5329\n",
      "step [1200/50000], loss = 5.5297\n",
      "step [1300/50000], loss = 5.5280\n",
      "step [1400/50000], loss = 5.5324\n",
      "step [1500/50000], loss = 5.5313\n",
      "step [1600/50000], loss = 5.5286\n",
      "step [1700/50000], loss = 5.5303\n",
      "step [1800/50000], loss = 5.5327\n",
      "step [1900/50000], loss = 5.5318\n",
      "step [2000/50000], loss = 5.5271\n",
      "step [2100/50000], loss = 5.5289\n",
      "step [2200/50000], loss = 5.5314\n",
      "step [2300/50000], loss = 5.5302\n",
      "step [2400/50000], loss = 5.5300\n",
      "step [2500/50000], loss = 5.5328\n",
      "step [2600/50000], loss = 5.5302\n",
      "step [2700/50000], loss = 5.5328\n",
      "step [2800/50000], loss = 5.5310\n",
      "step [2900/50000], loss = 5.5316\n",
      "step [3000/50000], loss = 5.5294\n",
      "step [3100/50000], loss = 5.5316\n",
      "step [3200/50000], loss = 5.5282\n",
      "step [3300/50000], loss = 5.5303\n",
      "step [3400/50000], loss = 5.5302\n",
      "step [3500/50000], loss = 5.5354\n",
      "step [3600/50000], loss = 5.5321\n",
      "step [3700/50000], loss = 5.5293\n",
      "step [3800/50000], loss = 5.5311\n",
      "step [3900/50000], loss = 5.5310\n",
      "step [4000/50000], loss = 5.5307\n",
      "step [4100/50000], loss = 5.5288\n",
      "step [4200/50000], loss = 5.5318\n",
      "step [4300/50000], loss = 5.5292\n",
      "step [4400/50000], loss = 5.5335\n",
      "step [4500/50000], loss = 5.5288\n",
      "step [4600/50000], loss = 5.5308\n",
      "step [4700/50000], loss = 5.5337\n",
      "step [4800/50000], loss = 5.5341\n",
      "step [4900/50000], loss = 5.5328\n",
      "step [5000/50000], loss = 5.5330\n",
      "step [5100/50000], loss = 5.5293\n",
      "step [5200/50000], loss = 5.5296\n",
      "step [5300/50000], loss = 5.5308\n",
      "step [5400/50000], loss = 5.5285\n",
      "step [5500/50000], loss = 5.5312\n",
      "step [5600/50000], loss = 5.5238\n",
      "step [5700/50000], loss = 5.5266\n",
      "step [5800/50000], loss = 5.5320\n",
      "step [5900/50000], loss = 5.5300\n",
      "step [6000/50000], loss = 5.5282\n",
      "step [6100/50000], loss = 5.5287\n",
      "step [6200/50000], loss = 5.5364\n",
      "step [6300/50000], loss = 5.5297\n",
      "step [6400/50000], loss = 5.5319\n",
      "step [6500/50000], loss = 5.5272\n",
      "step [6600/50000], loss = 5.5280\n",
      "step [6700/50000], loss = 5.5291\n",
      "step [6800/50000], loss = 5.5290\n",
      "step [6900/50000], loss = 5.5311\n",
      "step [7000/50000], loss = 5.5292\n",
      "step [7100/50000], loss = 5.5347\n",
      "step [7200/50000], loss = 5.5321\n",
      "step [7300/50000], loss = 5.5280\n",
      "step [7400/50000], loss = 5.5309\n",
      "step [7500/50000], loss = 5.5311\n",
      "step [7600/50000], loss = 5.5319\n",
      "step [7700/50000], loss = 5.5303\n",
      "step [7800/50000], loss = 5.5314\n",
      "step [7900/50000], loss = 5.5282\n",
      "step [8000/50000], loss = 5.5284\n",
      "step [8100/50000], loss = 5.5310\n",
      "step [8200/50000], loss = 5.5281\n",
      "step [8300/50000], loss = 5.5302\n",
      "step [8400/50000], loss = 5.5317\n",
      "step [8500/50000], loss = 5.5282\n",
      "step [8600/50000], loss = 5.5337\n",
      "step [8700/50000], loss = 5.5306\n",
      "step [8800/50000], loss = 5.5277\n",
      "step [8900/50000], loss = 5.5304\n",
      "step [9000/50000], loss = 5.5313\n",
      "step [9100/50000], loss = 5.5305\n",
      "step [9200/50000], loss = 5.5314\n",
      "step [9300/50000], loss = 5.5299\n",
      "step [9400/50000], loss = 5.5310\n",
      "step [9500/50000], loss = 5.5288\n",
      "step [9600/50000], loss = 5.5283\n",
      "step [9700/50000], loss = 5.5313\n",
      "step [9800/50000], loss = 5.5310\n",
      "step [9900/50000], loss = 5.5302\n",
      "step [10000/50000], loss = 5.5294\n",
      "step [10100/50000], loss = 5.5318\n",
      "step [10200/50000], loss = 5.5297\n",
      "step [10300/50000], loss = 5.5324\n",
      "step [10400/50000], loss = 5.5297\n",
      "step [10500/50000], loss = 5.5261\n",
      "step [10600/50000], loss = 5.5313\n",
      "step [10700/50000], loss = 5.5317\n",
      "step [10800/50000], loss = 5.5302\n",
      "step [10900/50000], loss = 5.5324\n",
      "step [11000/50000], loss = 5.5332\n",
      "step [11100/50000], loss = 5.5340\n",
      "step [11200/50000], loss = 5.5299\n",
      "step [11300/50000], loss = 5.5283\n",
      "step [11400/50000], loss = 5.5293\n",
      "step [11500/50000], loss = 5.5288\n",
      "step [11600/50000], loss = 5.5298\n",
      "step [11700/50000], loss = 5.5288\n",
      "step [11800/50000], loss = 5.5273\n",
      "step [11900/50000], loss = 5.5298\n",
      "step [12000/50000], loss = 5.5288\n",
      "step [12100/50000], loss = 5.5297\n",
      "step [12200/50000], loss = 5.5309\n",
      "step [12300/50000], loss = 5.5286\n",
      "step [12400/50000], loss = 5.5324\n",
      "step [12500/50000], loss = 5.5300\n",
      "step [12600/50000], loss = 5.5318\n",
      "step [12700/50000], loss = 5.5329\n",
      "step [12800/50000], loss = 5.5286\n",
      "step [12900/50000], loss = 5.5304\n",
      "step [13000/50000], loss = 5.5310\n",
      "step [13100/50000], loss = 5.5289\n",
      "step [13200/50000], loss = 5.5355\n",
      "step [13300/50000], loss = 5.5312\n",
      "step [13400/50000], loss = 5.5297\n",
      "step [13500/50000], loss = 5.5317\n",
      "step [13600/50000], loss = 5.5243\n",
      "step [13700/50000], loss = 5.5300\n",
      "step [13800/50000], loss = 5.5302\n",
      "step [13900/50000], loss = 5.5290\n",
      "step [14000/50000], loss = 5.5291\n",
      "step [14100/50000], loss = 5.5322\n",
      "step [14200/50000], loss = 5.5313\n",
      "step [14300/50000], loss = 5.5341\n",
      "step [14400/50000], loss = 5.5281\n",
      "step [14500/50000], loss = 5.5339\n",
      "step [14600/50000], loss = 5.5300\n",
      "step [14700/50000], loss = 5.5293\n",
      "step [14800/50000], loss = 5.5291\n",
      "step [14900/50000], loss = 5.5323\n",
      "step [15000/50000], loss = 5.5310\n",
      "step [15100/50000], loss = 5.5316\n",
      "step [15200/50000], loss = 5.5281\n",
      "step [15300/50000], loss = 5.5294\n",
      "step [15400/50000], loss = 5.5318\n",
      "step [15500/50000], loss = 5.5293\n",
      "step [15600/50000], loss = 5.5272\n",
      "step [15700/50000], loss = 5.5297\n",
      "step [15800/50000], loss = 5.5299\n",
      "step [15900/50000], loss = 5.5296\n",
      "step [16000/50000], loss = 5.5325\n",
      "step [16100/50000], loss = 5.5313\n",
      "step [16200/50000], loss = 5.5303\n",
      "step [16300/50000], loss = 5.5317\n",
      "step [16400/50000], loss = 5.5305\n",
      "step [16500/50000], loss = 5.5305\n",
      "step [16600/50000], loss = 5.5287\n",
      "step [16700/50000], loss = 5.5316\n",
      "step [16800/50000], loss = 5.5325\n",
      "step [16900/50000], loss = 5.5309\n",
      "step [17000/50000], loss = 5.5307\n",
      "step [17100/50000], loss = 5.5304\n",
      "step [17200/50000], loss = 5.5316\n",
      "step [17300/50000], loss = 5.5281\n",
      "step [17400/50000], loss = 5.5273\n",
      "step [17500/50000], loss = 5.5329\n",
      "step [17600/50000], loss = 5.5321\n",
      "step [17700/50000], loss = 5.5284\n",
      "step [17800/50000], loss = 5.5316\n",
      "step [17900/50000], loss = 5.5316\n",
      "step [18000/50000], loss = 5.5306\n",
      "step [18100/50000], loss = 5.5314\n",
      "step [18200/50000], loss = 5.5277\n",
      "step [18300/50000], loss = 5.5312\n",
      "step [18400/50000], loss = 5.5306\n",
      "step [18500/50000], loss = 5.5305\n",
      "step [18600/50000], loss = 5.5285\n",
      "step [18700/50000], loss = 5.5294\n",
      "step [18800/50000], loss = 5.5320\n",
      "step [18900/50000], loss = 5.5247\n",
      "step [19000/50000], loss = 5.5298\n",
      "step [19100/50000], loss = 5.5297\n",
      "step [19200/50000], loss = 5.5299\n",
      "step [19300/50000], loss = 5.5313\n",
      "step [19400/50000], loss = 5.5310\n",
      "step [19500/50000], loss = 5.5299\n",
      "step [19600/50000], loss = 5.5305\n",
      "step [19700/50000], loss = 5.5302\n",
      "step [19800/50000], loss = 5.5283\n",
      "step [19900/50000], loss = 5.5327\n",
      "step [20000/50000], loss = 5.5322\n",
      "step [20100/50000], loss = 5.5321\n",
      "step [20200/50000], loss = 5.5262\n",
      "step [20300/50000], loss = 5.5294\n",
      "step [20400/50000], loss = 5.5305\n",
      "step [20500/50000], loss = 5.5307\n",
      "step [20600/50000], loss = 5.5278\n",
      "step [20700/50000], loss = 5.5267\n",
      "step [20800/50000], loss = 5.5294\n",
      "step [20900/50000], loss = 5.5272\n",
      "step [21000/50000], loss = 5.5290\n",
      "step [21100/50000], loss = 5.5316\n",
      "step [21200/50000], loss = 5.5305\n",
      "step [21300/50000], loss = 5.5284\n",
      "step [21400/50000], loss = 5.5302\n",
      "step [21500/50000], loss = 5.5311\n",
      "step [21600/50000], loss = 5.5302\n",
      "step [21700/50000], loss = 5.5295\n",
      "step [21800/50000], loss = 5.5317\n",
      "step [21900/50000], loss = 5.5321\n",
      "step [22000/50000], loss = 5.5303\n",
      "step [22100/50000], loss = 5.5305\n",
      "step [22200/50000], loss = 5.5318\n",
      "step [22300/50000], loss = 5.5308\n",
      "step [22400/50000], loss = 5.5327\n",
      "step [22500/50000], loss = 5.5294\n",
      "step [22600/50000], loss = 5.5302\n",
      "step [22700/50000], loss = 5.5276\n",
      "step [22800/50000], loss = 5.5305\n",
      "step [22900/50000], loss = 5.5254\n",
      "step [23000/50000], loss = 5.5327\n",
      "step [23100/50000], loss = 5.5301\n",
      "step [23200/50000], loss = 5.5310\n",
      "step [23300/50000], loss = 5.5269\n",
      "step [23400/50000], loss = 5.5275\n",
      "step [23500/50000], loss = 5.5305\n",
      "step [23600/50000], loss = 5.5286\n",
      "step [23700/50000], loss = 5.5324\n",
      "step [23800/50000], loss = 5.5293\n",
      "step [23900/50000], loss = 5.5299\n",
      "step [24000/50000], loss = 5.5330\n",
      "step [24100/50000], loss = 5.5296\n",
      "step [24200/50000], loss = 5.5280\n",
      "step [24300/50000], loss = 5.5286\n",
      "step [24400/50000], loss = 5.5320\n",
      "step [24500/50000], loss = 5.5326\n",
      "step [24600/50000], loss = 5.5314\n",
      "step [24700/50000], loss = 5.5292\n",
      "step [24800/50000], loss = 5.5308\n",
      "step [24900/50000], loss = 5.5277\n",
      "step [25000/50000], loss = 5.5297\n",
      "step [25100/50000], loss = 5.5303\n",
      "step [25200/50000], loss = 5.5303\n",
      "step [25300/50000], loss = 5.5323\n",
      "step [25400/50000], loss = 5.5289\n",
      "step [25500/50000], loss = 5.5303\n",
      "step [25600/50000], loss = 5.5316\n",
      "step [25700/50000], loss = 5.5291\n",
      "step [25800/50000], loss = 5.5330\n",
      "step [25900/50000], loss = 5.5308\n",
      "step [26000/50000], loss = 5.5303\n",
      "step [26100/50000], loss = 5.5299\n",
      "step [26200/50000], loss = 5.5311\n",
      "step [26300/50000], loss = 5.5327\n",
      "step [26400/50000], loss = 5.5309\n",
      "step [26500/50000], loss = 5.5312\n",
      "step [26600/50000], loss = 5.5302\n",
      "step [26700/50000], loss = 5.5327\n",
      "step [26800/50000], loss = 5.5316\n",
      "step [26900/50000], loss = 5.5299\n",
      "step [27000/50000], loss = 5.5311\n",
      "step [27100/50000], loss = 5.5311\n",
      "step [27200/50000], loss = 5.5275\n",
      "step [27300/50000], loss = 5.5334\n",
      "step [27400/50000], loss = 5.5301\n",
      "step [27500/50000], loss = 5.5288\n",
      "step [27600/50000], loss = 5.5294\n",
      "step [27700/50000], loss = 5.5324\n",
      "step [27800/50000], loss = 5.5275\n",
      "step [27900/50000], loss = 5.5275\n",
      "step [28000/50000], loss = 5.5309\n",
      "step [28100/50000], loss = 5.5305\n",
      "step [28200/50000], loss = 5.5324\n",
      "step [28300/50000], loss = 5.5307\n",
      "step [28400/50000], loss = 5.5275\n",
      "step [28500/50000], loss = 5.5310\n",
      "step [28600/50000], loss = 5.5356\n",
      "step [28700/50000], loss = 5.5307\n",
      "step [28800/50000], loss = 5.5326\n",
      "step [28900/50000], loss = 5.5273\n",
      "step [29000/50000], loss = 5.5319\n",
      "step [29100/50000], loss = 5.5332\n",
      "step [29200/50000], loss = 5.5285\n",
      "step [29300/50000], loss = 5.5271\n",
      "step [29400/50000], loss = 5.5302\n",
      "step [29500/50000], loss = 5.5296\n",
      "step [29600/50000], loss = 5.5299\n",
      "step [29700/50000], loss = 5.5296\n",
      "step [29800/50000], loss = 5.5345\n",
      "step [29900/50000], loss = 5.5313\n",
      "step [30000/50000], loss = 5.5315\n",
      "step [30100/50000], loss = 5.5301\n",
      "step [30200/50000], loss = 5.5346\n",
      "step [30300/50000], loss = 5.5291\n",
      "step [30400/50000], loss = 5.5319\n",
      "step [30500/50000], loss = 5.5309\n",
      "step [30600/50000], loss = 5.5279\n",
      "step [30700/50000], loss = 5.5299\n",
      "step [30800/50000], loss = 5.5270\n",
      "step [30900/50000], loss = 5.5307\n",
      "step [31000/50000], loss = 5.5286\n",
      "step [31100/50000], loss = 5.5280\n",
      "step [31200/50000], loss = 5.5322\n",
      "step [31300/50000], loss = 5.5271\n",
      "step [31400/50000], loss = 5.5276\n",
      "step [31500/50000], loss = 5.5310\n",
      "step [31600/50000], loss = 5.5302\n",
      "step [31700/50000], loss = 5.5302\n",
      "step [31800/50000], loss = 5.5319\n",
      "step [31900/50000], loss = 5.5318\n",
      "step [32000/50000], loss = 5.5288\n",
      "step [32100/50000], loss = 5.5294\n",
      "step [32200/50000], loss = 5.5293\n",
      "step [32300/50000], loss = 5.5297\n",
      "step [32400/50000], loss = 5.5337\n",
      "step [32500/50000], loss = 5.5296\n",
      "step [32600/50000], loss = 5.5326\n",
      "step [32700/50000], loss = 5.5299\n",
      "step [32800/50000], loss = 5.5343\n",
      "step [32900/50000], loss = 5.5301\n",
      "step [33000/50000], loss = 5.5312\n",
      "step [33100/50000], loss = 5.5315\n",
      "step [33200/50000], loss = 5.5316\n",
      "step [33300/50000], loss = 5.5280\n",
      "step [33400/50000], loss = 5.5280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m encoder2\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# ======================= 3) 采样一批 (sample1, sample2) =======================\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     sample1, sample2 \u001b[38;5;241m=\u001b[39m \u001b[43msample_pairs_extra_dim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomp_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp_var\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# 假设在 GPU 上训练，可执行 .to(device)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     sample1 \u001b[38;5;241m=\u001b[39m sample1\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m, in \u001b[0;36msample_pairs_extra_dim\u001b[0;34m(comp1, comp2, N, comp_var)\u001b[0m\n\u001b[1;32m     41\u001b[0m count_d \u001b[38;5;241m=\u001b[39m mask_i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 从 comp2[d] 批量采样 -> 放到 sample2[mask_i]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m x2 \u001b[38;5;241m=\u001b[39m comp2[d]\u001b[38;5;241m.\u001b[39msample((count_d,))  \u001b[38;5;66;03m# shape (count_d, dim)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = ContrastiveLoss(temperature=0.07)\n",
    "\n",
    "encoder1 = encoder1.to(device)\n",
    "encoder2 = encoder2.to(device)\n",
    "encoder1.train()\n",
    "encoder2.train()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # ======================= 3) 采样一批 (sample1, sample2) =======================\n",
    "    sample1, sample2 = sample_pairs_extra_dim(\n",
    "        comp1=comp1, \n",
    "        comp2=comp2, \n",
    "        N=batch_size, \n",
    "        comp_var=comp_var\n",
    "    )\n",
    "    \n",
    "    # 假设在 GPU 上训练，可执行 .to(device)\n",
    "    sample1 = sample1.to(device)\n",
    "    sample2 = sample2.to(device)\n",
    "    sample1 = F.normalize(sample1, dim=-1)\n",
    "    sample2 = F.normalize(sample2, dim=-1)\n",
    "    \n",
    "    # ======================= 4) 前向传播 =======================\n",
    "    emb1 = encoder1(sample1)\n",
    "    emb2 = encoder2(sample2)\n",
    "    \n",
    "    loss = criterion(emb1, emb2)\n",
    "    \n",
    "    # ======================= 5) 反向传播 & 更新参数 =======================\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1) % 100 == 0:\n",
    "        print(f\"step [{step+1}/{num_steps}], loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_analysis_samples = 500\n",
    "sample1_analysis, sample2_analysis = sample_pairs_extra_dim(\n",
    "    comp1=comp1,\n",
    "    comp2=comp2,\n",
    "    N=num_analysis_samples,\n",
    "    comp_var=comp_var\n",
    ")\n",
    "sample1_analysis = sample1_analysis.to(device)\n",
    "sample2_analysis = sample2_analysis.to(device)\n",
    "\n",
    "encoder1.eval()\n",
    "encoder2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb1_all = encoder1(sample1_analysis)\n",
    "    emb2_all = encoder2(sample2_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_retrieval(image_features, text_features, num_captions=5):\n",
    "    \"\"\"\n",
    "    评估 image-to-text (I2T) 和 text-to-image (T2I) 的检索性能指标。\n",
    "    \n",
    "    Args:\n",
    "        image_features (torch.Tensor): shape 为 (N, D) 的图片特征张量，其中 N 为图片数量。\n",
    "        text_features (torch.Tensor): shape 为 (N * num_captions, D) 的文本特征张量，每张图片对应 num_captions 个 caption。\n",
    "        num_captions (int): 每张图片对应的 caption 数量（默认 5）。\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含以下键值对的字典：\n",
    "            {\n",
    "                'I2T_top1': float,  # 图片检索文本 Top1 准确率\n",
    "                'I2T_top5': float,  # 图片检索文本 Top5 准确率\n",
    "                'I2T_top10': float, # 图片检索文本 Top10 准确率\n",
    "                'T2I_top1': float,  # 文本检索图片 Top1 准确率\n",
    "                'T2I_top5': float,  # 文本检索图片 Top5 准确率\n",
    "                'T2I_top10': float, # 文本检索图片 Top10 准确率\n",
    "            }\n",
    "    \"\"\"\n",
    "    # 确保文本数量与图片数量及每张图片的 caption 数匹配\n",
    "    num_images = image_features.size(0)\n",
    "    assert text_features.size(0) == num_images * num_captions, \"文本特征数量与图片数量不匹配！\"\n",
    "\n",
    "    # 若未归一化，则先归一化特征（如果已归一化可省略）\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    # 计算相似度矩阵：shape 为 (N, N * num_captions)\n",
    "    similarity = image_features @ text_features.t()\n",
    "    \n",
    "    # 评估 image-to-text (I2T)\n",
    "    I2T_top1, I2T_top5, I2T_top10 = 0, 0, 0\n",
    "    for i in range(num_images):\n",
    "        sim_i = similarity[i]  # 第 i 张图片与所有文本之间的相似度\n",
    "        # 获取从大到小排序后的文本索引\n",
    "        sorted_indices = torch.argsort(sim_i, descending=True)\n",
    "        # 第 i 张图片的 ground truth 文本索引范围\n",
    "        gt_indices = list(range(i * num_captions, i * num_captions + num_captions))\n",
    "        # Top1 检索：如果 ground truth 中任一索引出现在前 1 个，则认为正确\n",
    "        if any(idx in sorted_indices[:1] for idx in gt_indices):\n",
    "            I2T_top1 += 1\n",
    "        # Top5 检索\n",
    "        if any(idx in sorted_indices[:5] for idx in gt_indices):\n",
    "            I2T_top5 += 1\n",
    "        # Top10 检索\n",
    "        if any(idx in sorted_indices[:10] for idx in gt_indices):\n",
    "            I2T_top10 += 1\n",
    "\n",
    "    I2T_top1_score = I2T_top1 / num_images\n",
    "    I2T_top5_score = I2T_top5 / num_images\n",
    "    I2T_top10_score = I2T_top10 / num_images\n",
    "\n",
    "    # 评估 text-to-image (T2I)\n",
    "    # 这里可以利用相似度矩阵的转置，shape 为 (N * num_captions, N)\n",
    "    similarity_t = similarity.t()\n",
    "    T2I_top1, T2I_top5, T2I_top10 = 0, 0, 0\n",
    "    for j in range(text_features.size(0)):\n",
    "        sim_j = similarity_t[j]  # 第 j 个文本与所有图片的相似度\n",
    "        sorted_indices = torch.argsort(sim_j, descending=True)\n",
    "        # 对于第 j 个文本，其对应图片索引为 j // num_captions\n",
    "        gt_image = j // num_captions\n",
    "        if gt_image in sorted_indices[:1]:\n",
    "            T2I_top1 += 1\n",
    "        if gt_image in sorted_indices[:5]:\n",
    "            T2I_top5 += 1\n",
    "        if gt_image in sorted_indices[:10]:\n",
    "            T2I_top10 += 1\n",
    "\n",
    "    total_texts = text_features.size(0)\n",
    "    T2I_top1_score = T2I_top1 / total_texts\n",
    "    T2I_top5_score = T2I_top5 / total_texts\n",
    "    T2I_top10_score = T2I_top10 / total_texts\n",
    "\n",
    "    results = {\n",
    "        'I2T_top1': I2T_top1_score,\n",
    "        'I2T_top5': I2T_top5_score,\n",
    "        'I2T_top10': I2T_top10_score,\n",
    "        'T2I_top1': T2I_top1_score,\n",
    "        'T2I_top5': T2I_top5_score,\n",
    "        'T2I_top10': T2I_top10_score,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  var1-var1\n",
      "0   I2T_top1      0.002\n",
      "1   I2T_top5      0.014\n",
      "2  I2T_top10      0.038\n",
      "3   T2I_top1      0.006\n",
      "4   T2I_top5      0.022\n",
      "5  T2I_top10      0.044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "retrieval_results = evaluate_retrieval(emb1_all, emb2_all, num_captions=1)\n",
    "\n",
    "coco_retrieval_data = {\n",
    "    \"Metric\": [\"I2T_top1\", \"I2T_top5\", \"I2T_top10\", \"T2I_top1\", \"T2I_top5\", \"T2I_top10\"],\n",
    "    \"var1-var1\": [\n",
    "        retrieval_results[\"I2T_top1\"],\n",
    "        retrieval_results[\"I2T_top5\"],\n",
    "        retrieval_results[\"I2T_top10\"],\n",
    "        retrieval_results[\"T2I_top1\"],\n",
    "        retrieval_results[\"T2I_top5\"],\n",
    "        retrieval_results[\"T2I_top10\"],\n",
    "    ],\n",
    "}\n",
    "df = pd.DataFrame(coco_retrieval_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_calc_similarity(image_features, text_features):\n",
    "\n",
    "    # ========== 1) 计算全局均值并归一化 ==========\n",
    "    # image 全局均值: (D,)\n",
    "    mean_image = image_features.mean(dim=0)\n",
    "    # text 全局均值:  (D,)\n",
    "    mean_text  = text_features.mean(dim=0)\n",
    "\n",
    "    # 归一化 (若想直接点乘当作余弦相似度, image/text_features 本身也需归一化)\n",
    "    mean_image_norm = mean_image / (mean_image.norm() + 1e-12)\n",
    "    mean_text_norm  = mean_text  / (mean_text.norm()  + 1e-12)\n",
    "\n",
    "    # ========== 2) 计算夹角 theta 并构造二维平面内的正交向量 ==========\n",
    "    # cos_angle = a·b\n",
    "    cos_angle = torch.dot(mean_image_norm, mean_text_norm)\n",
    "    # 防止浮点误差导致 acos 输入超出 [-1,1]\n",
    "    cos_angle = torch.clamp(cos_angle, -1.0, 1.0)\n",
    "    theta = torch.acos(cos_angle)  # 弧度\n",
    "\n",
    "    sin_angle = torch.sqrt(1 - cos_angle**2 + 1e-12)\n",
    "    # 在 (mean_image_norm, mean_text_norm) 所张平面上，构造与 mean_image_norm 正交的单位向量 v\n",
    "    v = (mean_text_norm - cos_angle * mean_image_norm) / (sin_angle + 1e-12)\n",
    "\n",
    "    # ========== 3) 在 (mean_image_norm, v) 平面内对 image_features 做旋转 ==========\n",
    "    # 投影系数\n",
    "    proj_a = image_features @ mean_image_norm  # (N,)\n",
    "    proj_v = image_features @ v                # (N,)\n",
    "\n",
    "    # 2D 旋转\n",
    "    # new_a = a*cosθ - v*sinθ\n",
    "    # new_v = a*sinθ + v*cosθ\n",
    "    rotated_proj_a = proj_a * torch.cos(theta) - proj_v * torch.sin(theta)  # (N,)\n",
    "    rotated_proj_v = proj_a * torch.sin(theta) + proj_v * torch.cos(theta)  # (N,)\n",
    "\n",
    "    # 在平面内的分量(旋转后)\n",
    "    rotated_parallel = (rotated_proj_a.unsqueeze(1) * mean_image_norm.unsqueeze(0)\n",
    "                      + rotated_proj_v.unsqueeze(1) * v.unsqueeze(0))\n",
    "\n",
    "    # 原本在平面内的分量\n",
    "    orig_parallel = (proj_a.unsqueeze(1) * mean_image_norm.unsqueeze(0)\n",
    "                   + proj_v.unsqueeze(1) * v.unsqueeze(0))\n",
    "\n",
    "    # 正交分量(不在平面内, 保持不变)\n",
    "    orthogonal_component = image_features - orig_parallel\n",
    "\n",
    "    # 旋转后的图像特征 (N, D)\n",
    "    rotated_image_features = rotated_parallel + orthogonal_component\n",
    "\n",
    "    # ========== 4) 计算相似度矩阵 (N, 5N) ==========\n",
    "    # 如果想用余弦相似度, 这里要保证 rotated_image_features 与 text_features 已各自归一化。\n",
    "    # 否则就是一般点乘。\n",
    "    similarity_matrix = rotated_image_features @ text_features.T  # (N, 5N)\n",
    "\n",
    "    # ========== 5) 通过广播为 \"正例\" 与 \"负例\" 构造布尔掩码 ==========\n",
    "    # 对第 i 行(图像 i), 正例对应的列区间是 [5*i, ..., 5*i+4]\n",
    "    #   => j_idx // 5 == i_idx\n",
    "\n",
    "    N = image_features.size(0)\n",
    "    i_idx = torch.arange(N, device=similarity_matrix.device).unsqueeze(1).expand(N, 5*N)\n",
    "    j_idx = torch.arange(5*N, device=similarity_matrix.device).unsqueeze(0).expand(N, 5*N)\n",
    "\n",
    "    pos_mask = (j_idx // 5 == i_idx)  # 形状 (N, 5N), True 表示匹配\n",
    "    # 所有正例相似度 => (N*5,) 向量\n",
    "    pos_sims = similarity_matrix[pos_mask]\n",
    "    # 如果你想分别取 \"每个图像 vs. 它的 5 条文本\" 的平均，可以 reshape => (N,5) 再 mean\n",
    "    # 这会先对每张图像5个caption做平均，再对 N 张图像平均\n",
    "    mean_pos = pos_sims.view(N, 5).mean()\n",
    "\n",
    "    # 负例相似度(不匹配)\n",
    "    neg_sims = similarity_matrix[~pos_mask]  # (N*(5N-5),)\n",
    "    mean_neg = neg_sims.mean()\n",
    "\n",
    "    return mean_pos.item(), mean_neg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [500, 2500] at index 1 does not match the shape of the indexed tensor [500, 500] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pos_sim, neg_sim \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_and_calc_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb1_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb2_all\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 64\u001b[0m, in \u001b[0;36mrotate_and_calc_similarity\u001b[0;34m(image_features, text_features)\u001b[0m\n\u001b[1;32m     62\u001b[0m pos_mask \u001b[38;5;241m=\u001b[39m (j_idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m i_idx)  \u001b[38;5;66;03m# 形状 (N, 5N), True 表示匹配\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 所有正例相似度 => (N*5,) 向量\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m pos_sims \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 如果你想分别取 \"每个图像 vs. 它的 5 条文本\" 的平均，可以 reshape => (N,5) 再 mean\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 这会先对每张图像5个caption做平均，再对 N 张图像平均\u001b[39;00m\n\u001b[1;32m     67\u001b[0m mean_pos \u001b[38;5;241m=\u001b[39m pos_sims\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [500, 2500] at index 1 does not match the shape of the indexed tensor [500, 500] at index 1"
     ]
    }
   ],
   "source": [
    "pos_sim, neg_sim = rotate_and_calc_similarity(emb1_all, emb2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
